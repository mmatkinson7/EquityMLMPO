{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee55903d",
   "metadata": {},
   "source": [
    "## Exploring Equity Classifications with Machine Learning\n",
    "### Proposal\n",
    "DATE: May 20, 2021\n",
    "\n",
    "TO: Annette Demchur, Rebecca Morgan\n",
    "\n",
    "FROM: Margaret Atkinson\n",
    "\n",
    "RE: Staff Initiated Study Proposal:\n",
    "\n",
    "#### Exploring Equity Classifications with Machine Learning\n",
    "\n",
    "I would like to conduct research to answer the following question: Could an\n",
    "unsupervised machine learning algorithm create groups of towns based on\n",
    "demographic information that would be useful to explore questions about equity? To\n",
    "explain, when we compare all towns that pass the minority threshold (or TAZs or block\n",
    "groups etc.) to all towns that do not, we may be missing the way the demographic\n",
    "variables interact and a multifactored grouping could allow us to explore the\n",
    "demographic towns with a more detailed approach without the blending nature of an\n",
    "index.\n",
    "\n",
    "This project would use python and specifically the Scikit-Learn python library to\n",
    "conduct unsupervised machine learning based on demographic data at the town level.\n",
    "The data would be demographic Census data from the American Community Survey 5-\n",
    "year estimates at minimum on the topics of: Race/Ethnicity, Limited English Proficiency,\n",
    "Median Income, Low Income, No Car Households, Population Density, Children, and\n",
    "Seniors. The product would be a geographic file that shows groupings of towns by\n",
    "demographic profile as found by the unsupervised machine learning algorithm as well\n",
    "as a written description of what each grouping represents.\n",
    "\n",
    "If the question is pursued and the results are useful - the ultimate intention (as a\n",
    "follow up project) would be to look at the way MPO distributes funding between the\n",
    "groups and within each group to look for disparities. Explanations of disparities could\n",
    "lead to a re-examination of the variables used in the algorithm in order to provide\n",
    "an additional check for equitable spending.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe51e47",
   "metadata": {},
   "source": [
    "Towns in the MPO\n",
    "BRMPO <- c(\"Beverly\",\"Boston\",\"Braintree\",\"Cambridge\",\"Chelsea\",\"Everett\",\"Framingham\",\"Franklin\",\"Gloucester\",\"Lynn\",\"Malden\",\"Marlborough\",\"Medford\",\"Melrose\",\"Newton\",\"Peabody\",\"Quincy\",\"Revere\",\"Salem\",\"Somerville\",\"Waltham\",\"Watertown\",\"Weymouth\",\"Woburn\",\"Acton\",\"Arlington\",\"Ashland\",\"Bedford\",\"Bellingham\",\"Belmont\",\"Bolton\",\"Boxborough\",\"Brookline\",\"Burlington\",\"Canton\",\"Carlisle\",\"Cohasset\",\"Concord\",\"Danvers\",\"Dedham\",\"Dover\",\"Essex\",\"Foxborough\",\"Hamilton\",\"Hingham\",\"Holbrook\",\"Holliston\",\"Hopkinton\",\"Hudson\",\"Hull\",\"Ipswichâ€,\"Lexington\",\"Lincoln\",\"Littleton\",\"Lynnfield\",\"Manchester-by-the-Sea\",\"Marblehead\",\"Marshfield\",\"Maynard\",\"Medfield\",           \"Medway\",\"Middleton\",\"Milford\",\"Millis\",\"Milton\",\"Nahant\",\"Natick\",\"Needham\",\"Norfolk\",\"North Reading\",\"Norwell\",\"Norwood\",\"Randolph\",\"Reading\",\"Rockland\",\"Rockport\",\"Saugus\",\"Scituate\",\"Sharon\",\"Sherborn\",\"Southborough\",\"Stoneham\",\"Stow\",\"Sudbury\",\"Swampscott\",\"Topsfield\",\"Wakefield\",\"Walpole\",\"Wayland\",\"Wellesley\",\"Wenham\",\"Weston\",\"Westwood\",\"Wilmington\",\"Winchester\",\"Winthrop\",\"Wrentham\")\n",
    "\n",
    "Algorithms\n",
    "K-means with K-means++ as initialization of seeding\n",
    "Only deterministic if the seeds are always the same, which K-means++ does not guarantee.\n",
    "DBSCAN\n",
    "\n",
    "\n",
    "Spectral Clustering\n",
    "Fully deterministic\n",
    "\n",
    "\n",
    "\n",
    "| Demographic | Tables | Fields | Calculation | Notes |\n",
    "| ----------- | ------ | ------ | ----------- | ----- |\n",
    "| Race/Ethnicity | ACS14: B02001 | B02001\\_001-B02001\\_002 | Total - White Alone|  |\n",
    "| Limited English Proficiency | ACS14: B16001 | B16001\\_005 + B16001\\_008 + B16001\\_011 + B16001\\_014 + B16001\\_017 + B16001\\_020 + B16001\\_023 + B16001\\_026 + B16001\\_029 + B16001\\_032 + B16001\\_035 + B16001\\_038 + B16001\\_041 + B16001\\_044 + B16001\\_047 + B16001\\_050 + B16001\\_053 + B16001\\_056 + B16001\\_059 + B16001\\_062 + B16001\\_065 + B16001\\_068 + B16001\\_071 + B16001\\_074 + B16001\\_077 + B16001\\_080 + B16001\\_083 + B16001\\_086 + B16001\\_089 + B16001\\_092 + B16001\\_095 + B16001\\_098 + B16001\\_101 + B16001\\_104 + B16001\\_107 + B16001\\_110 + B16001\\_113 + B16001\\_116 + B16001\\_119 | C16001 (less than very well)/(Total Population - (B01001\\_003 +B01001\\_027) |     \n",
    "|Median Income| ACS14: B19013 | B19013\\_001| | |                                                                               \n",
    "| % of HH with income below 200% of poverty line| ACS14: C17002 | C17002_002E + C17002_003E + C17002_004E + C17002_005E + C17002_006E + C17002_007E|||\n",
    "| Low Income Households| ACS14: B19001, B19025, B11001| All of B19001, B19025\\_001, B11001\\_001 | HH Income Ranges, Aggregate HH Income, Total HH || |\n",
    "| No Car Households| ACS14: B08201| B08201\\_002| HH with no vehicles available||\n",
    "| Population Density | https://jtleider.github.io/censusdata/api.html | B01001\\_001/AREA | Total Pop / AREA | These are shape, also use total population data |\n",
    "| Children | ACS14: B01001,  2010Cen: P12| (B01001\\_003 + B01001\\_004 + B01001\\_005 + B01001\\_006 + B01001\\_027 + B01001\\_028 + B01001\\_029 + B01001\\_030),  (P012\\_003 + P012\\_004 + P012\\_005 + P012\\_006 + P012\\_027 + P012\\_028 + P012\\_029 + P012\\_030) | Boys under 18 plus girls under 18 | 0-17 |\n",
    "| Population Over 5 | ACS14: B01001,  2010Cen: P12  | B01001\\_001 - (B01001\\_003 +B01001\\_027), P012\\_001 - (P012\\_003 + P012\\_027)  | Total Population - Children under 5 | 5+ |\n",
    "| Seniors | ACS14: B01001 | (B01001\\_020 + B01001\\_021 + B01001\\_022 + B01001\\_023 + B01001\\_024 + B01001\\_025) + (B01001\\_044 + B01001\\_045 + B01001\\_046 + B01001\\_047 + B01001\\_048 + B01001\\_049) | Men ages 65+ plus Women ages 65+ | 65+ |\n",
    "| People with Disabilities | ACS14: S1810 | S1810_C02_001E / S1810\\_C01\\_001E ( total pop with disability / total non institutionalized population) | Includes: Ambulatory, Hearing, Vision, Self-Care, Cognitive, Independent Living Difficulties |\n",
    "| Total Population | ACS14: B01001,  2010Cen: P1 | B01001\\_001, P01\\_001 | Includes those housed in group quarters |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9eed8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import censusdata\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from functools import reduce\n",
    "#import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1fac9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set some parameters to make display of data nicer\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8f65e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpoTowns = [\"Beverly\",\"Boston\",\"Braintree\",\"Cambridge\",\"Chelsea\",\"Everett\",\"Framingham\",\"Franklin\",\"Gloucester\",\n",
    "            \"Lynn\",\"Malden\",\"Marlborough\",\"Medford\",\"Melrose\",\"Newton\",\"Peabody\",\"Quincy\",\"Revere\",\"Salem\",\"Somerville\",\n",
    "            \"Waltham\",\"Watertown\",\"Weymouth\",\"Woburn\",\"Acton\",\"Arlington\",\"Ashland\",\"Bedford\",\"Bellingham\",\"Belmont\",\n",
    "            \"Bolton\",\"Boxborough\",\"Brookline\",\"Burlington\",\"Canton\",\"Carlisle\",\"Cohasset\",\"Concord\",\"Danvers\",\"Dedham\",\n",
    "            \"Dover\",\"Essex\",\"Foxborough\",\"Hamilton\",\"Hingham\",\"Holbrook\",\"Holliston\",\"Hopkinton\",\"Hudson\",\"Hull\",\"Ipswich\",\n",
    "            \"Lexington\",\"Lincoln\",\"Littleton\",\"Lynnfield\",\"Manchester-by-the-Sea\",\"Marblehead\",\"Marshfield\",\"Maynard\",\n",
    "            \"Medfield\", \"Medway\",\"Middleton\",\"Milford\",\"Millis\",\"Milton\",\"Nahant\",\"Natick\",\"Needham\",\"Norfolk\",\n",
    "            \"North Reading\",\"Norwell\",\"Norwood\",\"Randolph\",\"Reading\",\"Rockland\",\"Rockport\",\"Saugus\",\"Scituate\",\n",
    "            \"Sharon\",\"Sherborn\",\"Southborough\",\"Stoneham\",\"Stow\",\"Sudbury\",\"Swampscott\",\"Topsfield\",\"Wakefield\",\"Walpole\",\n",
    "            \"Wayland\",\"Wellesley\",\"Wenham\",\"Weston\",\"Westwood\",\"Wilmington\",\"Winchester\",\"Winthrop\",\"Wrentham\"]\n",
    "\n",
    "mpoNums = ['09175','39765','41515','44105','50250','04930','17405','24820','14640','74175','16495','60785','41690','55745',\n",
    "          '55955','01605','15060','43895','80510','11000','56130','62535','02130','07350','24925','73790','11525','31540',\n",
    "          '39625','61380','67665','80230','09840','35425','68260','72215','81035','77255','05070','35215','68050','39835',\n",
    "          '40115','72600','00380','37875','31085','06365','41165','56585','07000','13205','30700','05595','21850','37995',\n",
    "          '43580','57880','40430','52490','07740','78972','81005','37560','68645','74595','59105','60015','38400','16250',\n",
    "          '37490','70150','26150','27900','50145','38855','60330','30210','31645','25172','21990','48955','45560','57775',\n",
    "          '32310','41095','73440','11315','46050','72495','39975','30455','82315','78690','35950','38715','63165']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2f7c5",
   "metadata": {},
   "source": [
    "## Finding Tables and Fields Resources\n",
    "\n",
    "https://www.census.gov/prod/cen2010/doc/sf1.pdf\n",
    "\n",
    "https://www.census.gov/programs-surveys/acs/technical-documentation/table-shells.2014.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f836f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of fields needed for each calculation\n",
    "#ACS 2014 columns\n",
    "race = ['B02001_001E','B02001_002E'] #universe = total population\n",
    "lep = ['B16001_005E','B16001_008E','B16001_011E','B16001_014E','B16001_017E','B16001_020E','B16001_023E','B16001_026E',\n",
    "       'B16001_029E','B16001_032E','B16001_035E','B16001_038E','B16001_041E','B16001_044E','B16001_047E','B16001_050E',\n",
    "       'B16001_053E','B16001_056E','B16001_059E','B16001_062E','B16001_065E','B16001_068E','B16001_071E','B16001_074E',\n",
    "       'B16001_077E','B16001_080E','B16001_083E','B16001_086E','B16001_089E','B16001_092E','B16001_095E','B16001_098E',\n",
    "       'B16001_101E','B16001_104E','B16001_107E','B16001_110E','B16001_113E','B16001_116E','B16001_119E'] #universe = population > age 5\n",
    "medinc = ['B19013_001E'] #No Universe needed, but HH\n",
    "povPeop = ['C17002_002E','C17002_003E','C17002_004E','C17002_005E','C17002_006E','C17002_007E']\n",
    "nocar = ['B08201_002E'] #Universe = Households\n",
    "u18 = ['B01001_003E','B01001_004E','B01001_005E','B01001_006E','B01001_027E','B01001_028E',\n",
    "       'B01001_029E','B01001_030E'] #universe = total population\n",
    "sen = ['B01001_020E','B01001_021E','B01001_022E','B01001_023E','B01001_024E','B01001_025E',\n",
    "       'B01001_044E','B01001_045E','B01001_046E','B01001_047E','B01001_048E','B01001_049E']#universe = total population\n",
    "dis = ['S1810_C02_001E','S1810_C01_001E'] #universe = total NON institutionalized population\n",
    "acsHH = ['B11001_001E']\n",
    "acsPlus5 = ['B01001_001E','B01001_003E', 'B01001_027E']\n",
    "acsTotPop =  ['B01001_001E']\n",
    "\n",
    "#decennial census columns\n",
    "totpop = ['P001_001E']\n",
    "plus5 = ['P012_0001E','P012_0003E','P012_0027E']\n",
    "hh = ['P018_0001E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a97e2",
   "metadata": {},
   "source": [
    "### Grab ACS Data, Brief Clean, and Sum if Necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7ccf852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################GRAB ACS DATA###################################################\n",
    "#MINORITY\n",
    "#get table and reset index so that county sub is a field called muni\n",
    "minority = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   race).reset_index().rename(columns={'index':'muni'})\n",
    "\n",
    "#create the actual minority field\n",
    "minority['Minority#'] = minority['B02001_001E'] - minority['B02001_002E']\n",
    "#filter down to just what is in the MPO\n",
    "minority=minority[minority.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "#LEP\n",
    "limEngProf = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   lep).reset_index().rename(columns={'index':'muni'})\n",
    "\n",
    "#create the actual LEP field\n",
    "limEngProf['LEP#'] = limEngProf[list(limEngProf.columns)[:-1]].sum(axis=1)\n",
    "\n",
    "#filter down to just what is in the MPO\n",
    "limEngProf=limEngProf[limEngProf.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "#MEDIAN INCOME\n",
    "medIncome = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   medinc).reset_index().rename(columns={'index':'muni', 'B19013_001E':'MedianIncome'})\n",
    "#filter down to just what is in the MPO\n",
    "medIncome=medIncome[medIncome.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "\n",
    "#PEOPLE LIVING IN HOUSEHOLDS BELOW 200% OF THE POVERTY LINE\n",
    "povHH = censusdata.download('acs5',2014,censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), \n",
    "                                                              ('county subdivision', '*')]), \n",
    "                            povPeop).reset_index().rename(columns={'index':'muni'})\n",
    "#create the actual HH Pov field\n",
    "povHH['POV#'] = povHH[list(povHH.columns)[:-1]].sum(axis=1)\n",
    "\n",
    "#filter down to just what is in the MPO\n",
    "povHH=povHH[povHH.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "\n",
    "#NO CAR HOUSEHOLDS\n",
    "noCarHH = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   nocar).reset_index().rename(columns={'index':'muni', 'B08201_002E':'NoCarHH#'})\n",
    "#filter down to just what is in the MPO\n",
    "noCarHH =noCarHH[noCarHH.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "#CHILDREN\n",
    "kids = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   u18).reset_index().rename(columns={'index':'muni'})\n",
    "\n",
    "#create the actual kids field\n",
    "kids['Under18#'] = kids[list(kids.columns)[:-1]].sum(axis=1)\n",
    "\n",
    "#filter down to just what is in the MPO\n",
    "kids=kids[kids.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "#SENIORS\n",
    "seniors = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   sen).reset_index().rename(columns={'index':'muni'})\n",
    "\n",
    "#create the actual LEP field\n",
    "seniors['Over65#'] = seniors[list(seniors.columns)[:-1]].sum(axis=1)\n",
    "\n",
    "#filter down to just what is in the MPO\n",
    "seniors=seniors[seniors.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "#DISABILITY\n",
    "disability = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                 dis,'e4bec76221ba04c7df76c7c580659bf1f54ed2c1',\n",
    "                                 'subject').reset_index().rename(columns={'index':'muni','S1810_C02_001E':'Disability#'})\n",
    "#filter down to just what is in the MPO\n",
    "disability=disability[disability.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "#universe in same table pretty much only so do %calc here\n",
    "disability['Disability%'] = disability['Disability#']/disability['S1810_C01_001E']\n",
    "\n",
    "\n",
    "#HOUSEHOLDS \n",
    "households = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   acsHH).reset_index().rename(columns={'index':'muni', 'B11001_001E':'Households#'})\n",
    "#filter down to just what is in the MPO\n",
    "households =households[households.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "#OVER FIVE\n",
    "#CHILDREN\n",
    "over5 = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   acsPlus5).reset_index().rename(columns={'index':'muni'})\n",
    "\n",
    "#create the actual Over 5 field\n",
    "over5['Over5#'] = (over5['B01001_001E'] - (over5['B01001_003E'] + over5['B01001_027E']))\n",
    "\n",
    "#filter down to just what is in the MPO\n",
    "over5=over5[over5.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]\n",
    "\n",
    "\n",
    "#TOTAL POPULATION\n",
    "acsPop = censusdata.download('acs5',2014,\n",
    "                    censusdata.censusgeo([('state', '25'), ('county','017,021,025,009,023,027' ), ('county subdivision', '*')]),\n",
    "                   acsTotPop).reset_index().rename(columns={'index':'muni', 'B01001_001E':'TotalPopulation'})\n",
    "#filter down to just what is in the MPO\n",
    "acsPop =acsPop[acsPop.apply(lambda r: any([town in str(r[0]) for town in mpoNums]), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3f5f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge ACS data into one dataframe and make %\n",
    "#collect all the data (and filter)\n",
    "acsdata = [minority[['muni', 'Minority#']], limEngProf[['muni', 'LEP#']], medIncome[['muni', 'MedianIncome']], \n",
    "           povHH[['muni','POV#']], noCarHH[['muni', 'NoCarHH#']], kids[['muni', 'Under18#']], seniors[['muni', 'Over65#']], \n",
    "           disability[['muni', 'Disability#', 'Disability%']], households[['muni','Households#']], over5[['muni','Over5#']], \n",
    "           acsPop[['muni','TotalPopulation']]]\n",
    "#actually do the merging\n",
    "acsDF = reduce(lambda  left,right: pd.merge(left,right,on=['muni'], how='outer'), acsdata)\n",
    "\n",
    "#make the % fields\n",
    "acsDF['Minority%'] = acsDF['Minority#']/acsDF['TotalPopulation']\n",
    "acsDF['LEP%'] = acsDF['LEP#']/acsDF['Over5#']\n",
    "acsDF['noCarHH%'] = acsDF['NoCarHH#']/acsDF['Households#']\n",
    "acsDF['Under18%'] = acsDF['Under18#']/acsDF['TotalPopulation']\n",
    "acsDF['Over65%'] = acsDF['Over65#']/acsDF['TotalPopulation']\n",
    "acsDF['pov%'] = acsDF['POV#']/acsDF['TotalPopulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "59041b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in shapefile for area for population density\n",
    "cousub= gpd.read_file(r'C:\\Users\\AtkinsonM\\OneDrive - Commonwealth of Massachusetts\\Documents\\Jupyter_Home\\tl_2010_25_cousub10')\n",
    "\n",
    "#get area in sq miles (default to square meters because of CRS)\n",
    "cousub['Area'] = cousub.area*0.00000038610215855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f90ae9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a join field for bringing in the area from shapefile\n",
    "acsDF['County_Sub'] = acsDF.muni.astype(str).str.slice(-5, None)\n",
    "\n",
    "#join area to attribute table\n",
    "allvarDF = pd.merge(acsDF,cousub[['COUSUBFP10','Area']],left_on = 'County_Sub', right_on='COUSUBFP10', how='left')\n",
    "\n",
    "#create population density field (in people per square mile)\n",
    "allvarDF['PopDen']=allvarDF['TotalPopulation']/allvarDF['Area']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "219e5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "allvarDF.to_csv(r'C:\\Users\\AtkinsonM\\Downloads\\vartest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f7502c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8.23e-03\n",
       "1      3.94e-03\n",
       "2      1.13e-02\n",
       "3      1.02e-02\n",
       "4      5.75e-03\n",
       "         ...   \n",
       "352    5.07e-03\n",
       "353    4.24e-03\n",
       "354    4.64e-03\n",
       "355    1.40e-03\n",
       "356    5.92e-03\n",
       "Length: 357, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cousub.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8bdc5",
   "metadata": {},
   "source": [
    "### Grab Census Data, Brief Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86918d",
   "metadata": {},
   "source": [
    "Notes:\n",
    "1. Bring in Census Data\n",
    "3. Create raw #'s by conforming to census data\n",
    "4. Prep for ML\n",
    "5. Histograms of variables\n",
    "6. Elbow diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92aa2f1",
   "metadata": {},
   "source": [
    "## Machine Learning Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a747a",
   "metadata": {},
   "source": [
    "### Histograms of Variables\n",
    "Make histograms of all the variables to see what the range looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25eceafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minority %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea692c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEP %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Car Households\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e00a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population Density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a393a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Children \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seniors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada96c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# People with Disabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d107f",
   "metadata": {},
   "source": [
    "### Make Elbow Diagram for K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c24411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make elbow diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f6b55",
   "metadata": {},
   "source": [
    "### Try K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29a00508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d656bc8",
   "metadata": {},
   "source": [
    "### Try DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24cd40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb0a3b",
   "metadata": {},
   "source": [
    "### Try Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f558f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
